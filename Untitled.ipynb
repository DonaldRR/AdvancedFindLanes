{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lanes Finding\n",
    " The goals of project are:\n",
    "1. Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "2. Apply a distortion correction to raw images.\n",
    "3. Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "4. Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "5. Detect lane pixels and fit to find the lane boundary.\n",
    "6. Determine the curvature of the lane and vehicle position with respect to center.\n",
    "7. Warp the detected lane boundaries back onto the original image.\n",
    "8. Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Camera Calibration Matrix\n",
    "# Compute Distortion Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('./camera_cal/calibration*.jpg')\n",
    "img_size = None\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    img_size = img.shape\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, mtx, dist, revecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, (img_size[1], img_size[0]), None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/donald/anaconda3/envs/tf36/lib/python3.6/site-packages/sklearn/linear_model/base.py:509: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  linalg.lstsq(X, y)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "images = glob.glob('./test_images/*.jpg')\n",
    "\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Undistortion\n",
    "    dst = cv2.undistort(img, mtx, dist)\n",
    "    dst_ = copy.deepcopy(dst)\n",
    "    \n",
    "    # Thresholding with color\n",
    "    hls_thresh_img = hls_select(dst, thresh2=(40, 255), thresh3=(90, 255))\n",
    "    mask_color_img = np.ones_like(dst) * 255\n",
    "    \n",
    "    # Color (S,L) enhancement\n",
    "    dst = cv2.cvtColor(dst, cv2.COLOR_RGB2HLS)\n",
    "    dst[(hls_thresh_img == 1), 1:3] += 70\n",
    "    dst = cv2.cvtColor(dst, cv2.COLOR_HLS2RGB)\n",
    "    dst = cv2.GaussianBlur(dst, (3, 3), 0)\n",
    "    \n",
    "    # Thresholding image with gradients\n",
    "    img_sobelx = abs_sobel_thresh(dst, 'x', 20, 255)\n",
    "    img_sobely = abs_sobel_thresh(dst, 'y', 40, 255)\n",
    "    img_mag = mag_thresh(dst, 7, (40, 255))\n",
    "    img_dir = dir_threshold(dst, 5, (0.7, 1.3))\n",
    "    \n",
    "    # Combine thresholded images\n",
    "    binary_output = np.zeros_like(img[:,:,0])\n",
    "    binary_output[((img_sobelx == 1) & (img_sobely == 1)) | (hls_thresh_img == 1)] = 1\n",
    "    \n",
    "    # Region masking\n",
    "    y_size, x_size = img.shape[0], img.shape[1]\n",
    "    vertices = np.array([[(x_size/20, y_size), \n",
    "                          (x_size*15/31, y_size*12/20), \n",
    "                          (x_size*16/31, y_size*12/20), \n",
    "                          (x_size*19/20, y_size)]], dtype=np.int32)\n",
    "    mask_img = region_of_interest(binary_output, vertices)\n",
    "#     mask_img = cv2.fillPoly(mask_img, \n",
    "#                             np.array([[[x_size*0.2, y_size], [x_size/2, y_size*0.7], [x_size*0.8, y_size]]], \n",
    "#                             dtype=np.int32), 0)\n",
    "    \n",
    "    # Finding lines with Hough Alg.\n",
    "    mask_img, pts = hough_lines(mask_img, rho=2, theta=np.pi/180, min_line_len=20, max_line_gap=30, threshold=10)\n",
    "    binary_output_ = np.zeros_like(mask_img[:,:,0])\n",
    "    binary_output_[(binary_output == 1) & (cv2.cvtColor(mask_img, cv2.COLOR_RGB2GRAY) == 255)] = 1  \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Draw\n",
    "    color_binary_output_ = binary_output_.copy()\n",
    "    color_binary_output_[0:int(y_size*0.65), :] = 0\n",
    "    lanes_overlay = np.zeros_like(dst_)\n",
    "    lanes_overlay[color_binary_output_ == 1] = [255, 0, 0]\n",
    "    \n",
    "    overlay = dst_.copy()\n",
    "    pts = np.array(pts, np.int32)\n",
    "    cv2.fillPoly(overlay,[pts],(0,255,0))\n",
    "    cv2.addWeighted(overlay, 0.3, dst_, 0.7, 0, dst_)\n",
    "    cv2.addWeighted(lanes_overlay, 1.0, dst_, 1.0, 0, dst_)\n",
    "    \n",
    "    # Warp\n",
    "    margin_x = 300\n",
    "    margin_y_top = 0\n",
    "    size_x, size_y = img.shape[1], img.shape[0]\n",
    "    warp_img = warper(binary_output_, np.float32(pts), np.float32([[margin_x, margin_y_top], \n",
    "                                  [size_x - margin_x, margin_y_top], \n",
    "                                  [size_x - margin_x, size_y], \n",
    "                                  [margin_x, size_y]]))\n",
    "\n",
    "    # Curvature calculation\n",
    "    poly_warp_img, ploty, left_fit, right_fit = fit_polynomial(warp_img)\n",
    "    left_curv, right_curv = measure_curvature_pixels(ploty, left_fit, right_fit)\n",
    "#     print(left_curv, right_curv)\n",
    "    \n",
    "    # Save images\n",
    "#     plt.imsave('./output_images/sobelx/'+'sobelx_'+os.path.split(fname)[-1], img_sobelx, cmap='gray')\n",
    "#     plt.imsave('./output_images/sobely/'+'sobely_'+os.path.split(fname)[-1], img_sobely, cmap='gray')\n",
    "#     plt.imsave('./output_images/mag/'+'mag_'+os.path.split(fname)[-1], img_mag, cmap='gray')\n",
    "#     plt.imsave('./output_images/dir/'+'dir_'+os.path.split(fname)[-1], img_dir, cmap='gray')\n",
    "#     plt.imsave('./output_images/hls/'+'hls_'+os.path.split(fname)[-1], hls_thresh_img, cmap='gray')\n",
    "#     plt.imsave('./output_images/combo/'+'combo_'+os.path.split(fname)[-1], binary_output, cmap='gray')\n",
    "#     plt.imsave('./output_images/undistort/'+'undistort_'+os.path.split(fname)[-1], dst)\n",
    "    plt.imsave('./output_images/draw/'+os.path.split(fname)[-1], dst_)\n",
    "    plt.imsave('./output_images/mask/'+os.path.split(fname)[-1], mask_img)\n",
    "#     plt.imsave('./output_images/color_change/'+os.path.split(fname)[-1], dst)\n",
    "    plt.imsave('./output_images/weighted/'+os.path.split(fname)[-1], weighted_img(dst_, mask_img))\n",
    "    plt.imsave('./output_images/warp/'+os.path.split(fname)[-1], warp_img, cmap='gray')\n",
    "    plt.imsave('./output_images/precise_combo/'+os.path.split(fname)[-1], binary_output_, cmap='gray')\n",
    "    plt.imsave('./output_images/fit_poly/'+os.path.split(fname)[-1], poly_warp_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(img):\n",
    "    \n",
    "#     img = cv2.imread(fname)\n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Undistortion\n",
    "    dst = cv2.undistort(img, mtx, dist)\n",
    "    dst_ = copy.deepcopy(dst)\n",
    "    \n",
    "    # Color thresholding\n",
    "    hls_thresh_img = hls_select(dst, thresh2=(40, 255), thresh3=(90, 255))\n",
    "    mask_color_img = np.ones_like(dst) * 255\n",
    "    \n",
    "    # Color (S,L) enhancement\n",
    "    dst = cv2.cvtColor(dst, cv2.COLOR_RGB2HLS)\n",
    "    dst[(hls_thresh_img == 1), 1:3] += 70\n",
    "    dst = cv2.cvtColor(dst, cv2.COLOR_HLS2RGB)\n",
    "    dst = cv2.GaussianBlur(dst, (3, 3), 0)\n",
    "    \n",
    "    # Gradients thresholding\n",
    "    img_sobelx = abs_sobel_thresh(dst, 'x', 20, 255)\n",
    "    img_sobely = abs_sobel_thresh(dst, 'y', 40, 255)\n",
    "    img_mag = mag_thresh(dst, 7, (40, 255))\n",
    "    img_dir = dir_threshold(dst, 5, (0.7, 1.3))\n",
    "    \n",
    "    # Threshold combination\n",
    "    binary_output = np.zeros_like(img[:,:,0])\n",
    "    binary_output[((img_sobelx == 1) & (img_sobely == 1)) | (hls_thresh_img == 1)] = 1\n",
    "    \n",
    "    # Region masking\n",
    "    y_size, x_size = img.shape[0], img.shape[1]\n",
    "    vertices = np.array([[(x_size/20, y_size), \n",
    "                          (x_size*15/31, y_size*12/20), \n",
    "                          (x_size*16/31, y_size*12/20), \n",
    "                          (x_size*19/20, y_size)]], dtype=np.int32)\n",
    "    mask_img = region_of_interest(binary_output, vertices)\n",
    "#     mask_img = cv2.fillPoly(mask_img, \n",
    "#                             np.array([[[x_size*0.2, y_size], [x_size/2, y_size*0.7], [x_size*0.8, y_size]]], \n",
    "#                             dtype=np.int32), 0)\n",
    "    \n",
    "    # Finding lines with Hough Alg.\n",
    "    mask_img, pts = hough_lines(mask_img, rho=2, theta=np.pi/180, min_line_len=20, max_line_gap=30, threshold=10)\n",
    "    binary_output_ = np.zeros_like(mask_img[:,:,0])\n",
    "    binary_output_[(binary_output == 1) & (cv2.cvtColor(mask_img, cv2.COLOR_RGB2GRAY) == 255)] = 1    \n",
    "    \n",
    "    \n",
    "    # Draw\n",
    "    color_binary_output_ = binary_output_.copy()\n",
    "    color_binary_output_[0:int(y_size*0.65), :] = 0\n",
    "    lanes_overlay = np.zeros_like(dst_)\n",
    "    lanes_overlay[color_binary_output_ == 1] = [255, 0, 0]\n",
    "    \n",
    "    overlay = dst_.copy()\n",
    "    pts = np.array(pts, np.int32)\n",
    "    cv2.fillPoly(overlay,[pts],(0,255,0))\n",
    "    cv2.addWeighted(overlay, 0.3, dst_, 0.7, 0, dst_)\n",
    "    cv2.addWeighted(lanes_overlay, 1.0, dst_, 1.0, 0, dst_)\n",
    "    \n",
    "    # Warp\n",
    "    margin_x = 300\n",
    "    margin_y_top = 0\n",
    "    warp_img = warper(binary_output_, np.float32(pts), np.float32([[margin_x, margin_y_top], \n",
    "                                  [x_size - margin_x, margin_y_top], \n",
    "                                  [x_size - margin_x, y_size], \n",
    "                                  [margin_x, y_size]]))\n",
    "\n",
    "    # Curvature calculation\n",
    "    poly_warp_img, ploty, left_fit, right_fit = fit_polynomial(warp_img)\n",
    "    left_curv, right_curv = measure_curvature_pixels(ploty, left_fit, right_fit)\n",
    "    \n",
    "    # Create canvas and fill 2 images per frame\n",
    "    canvas = np.zeros((y_size, x_size, 3))\n",
    "    binary_output_ = cv2.resize(binary_output_, (int(x_size * 0.5), int(y_size * 0.5)))\n",
    "    dst_ = cv2.resize(dst_, (int(x_size * 0.5), int(y_size * 0.5)))\n",
    "    canvas[0:dst_.shape[0], \n",
    "           int(binary_output_.shape[1]*0.5):int(binary_output_.shape[1]*0.5)+binary_output_.shape[1],:] = \\\n",
    "    cv2.cvtColor(binary_output_, cv2.COLOR_GRAY2RGB)\n",
    "    canvas[0+dst_.shape[0]:dst_.shape[0]+binary_output_.shape[0], \n",
    "           int(binary_output_.shape[1]*0.5):int(binary_output_.shape[1]*0.5)+binary_output_.shape[1],:] = dst_\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    return canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video processed_project_video.mp4\n",
      "[MoviePy] Writing video processed_project_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 409/1261 [02:05<05:16,  2.69it/s]"
     ]
    }
   ],
   "source": [
    "white_output = 'processed_project_video.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
