{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lanes Finding\n",
    " The goals of project are:\n",
    "1. Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "2. Apply a distortion correction to raw images.\n",
    "3. Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "4. Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "5. Detect lane pixels and fit to find the lane boundary.\n",
    "6. Determine the curvature of the lane and vehicle position with respect to center.\n",
    "7. Warp the detected lane boundaries back onto the original image.\n",
    "8. Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Camera Calibration Matrix\n",
    "# Compute Distortion Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('./camera_cal/calibration*.jpg')\n",
    "img_size = None\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    img_size = img.shape\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, mtx, dist, revecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, (img_size[1], img_size[0]), None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/donald/anaconda3/envs/tf36/lib/python3.6/site-packages/sklearn/linear_model/base.py:509: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  linalg.lstsq(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img:test6.jpg 's curvature:2286.446372194378\n",
      "img:test5.jpg 's curvature:1298.2276279009525\n",
      "img:test4.jpg 's curvature:1937.9239865121228\n",
      "img:test1.jpg 's curvature:1562.2665306166932\n",
      "img:test3.jpg 's curvature:4240.6935697438\n",
      "img:test2.jpg 's curvature:1064.9371390194515\n",
      "img:straight_lines2.jpg 's curvature:22912.560874077568\n",
      "img:straight_lines1.jpg 's curvature:3032.3196465218066\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "images = glob.glob('./test_images/*.jpg')\n",
    "\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_name = os.path.split(fname)[-1]\n",
    "    \n",
    "    # Undistortion\n",
    "    dst = cv2.undistort(img, mtx, dist)\n",
    "    plt.imsave('./write_up_images/undistort_'+img_name, dst)\n",
    "    dst_ = copy.deepcopy(dst)\n",
    "    \n",
    "    # Thresholding with color\n",
    "    hls_thresh_img = hls_select(dst, thresh2=(40, 255), thresh3=(90, 255))\n",
    "    plt.imsave('./write_up_images/color_thresh_'+img_name, hls_thresh_img, cmap='gray')\n",
    "    mask_color_img = np.ones_like(dst) * 255\n",
    "    \n",
    "    # Color (S,L) enhancement\n",
    "    dst = cv2.cvtColor(dst, cv2.COLOR_RGB2HLS)\n",
    "    dst[(hls_thresh_img == 1), 1:3] += 70\n",
    "    dst = cv2.cvtColor(dst, cv2.COLOR_HLS2RGB)\n",
    "    plt.imsave('./write_up_images/color_enhance_'+img_name, dst)\n",
    "    dst = cv2.GaussianBlur(dst, (3, 3), 0)\n",
    "    plt.imsave('./write_up_images/blur_'+img_name, dst)\n",
    "    \n",
    "    # Thresholding image with gradients\n",
    "    img_sobelx = abs_sobel_thresh(dst, 'x', 20, 255)\n",
    "    plt.imsave('./write_up_images/sobelx_'+img_name, img_sobelx, cmap='gray')\n",
    "    img_sobely = abs_sobel_thresh(dst, 'y', 40, 255)\n",
    "    plt.imsave('./write_up_images/sobely_'+img_name, img_sobely, cmap='gray')\n",
    "    img_mag = mag_thresh(dst, 7, (40, 255))\n",
    "    plt.imsave('./write_up_images/mag_'+img_name, img_mag, cmap='gray')\n",
    "    img_dir = dir_threshold(dst, 5, (0.7, 1.3))\n",
    "    plt.imsave('./write_up_images/dir_'+img_name, img_dir, cmap='gray')\n",
    "    \n",
    "    # Combine thresholded images\n",
    "    binary_output = np.zeros_like(img[:,:,0])\n",
    "    binary_output[((img_sobelx == 1) & (img_sobely == 1)) | (hls_thresh_img == 1)] = 1\n",
    "    plt.imsave('./write_up_images/combo_'+img_name, binary_output, cmap='gray')\n",
    "    \n",
    "    # Region masking\n",
    "    y_size, x_size = img.shape[0], img.shape[1]\n",
    "    vertices = np.array([[(x_size*0.05, y_size), \n",
    "                          (x_size*0.40, y_size*0.65), \n",
    "                          (x_size*0.63, y_size*0.65), \n",
    "                          (x_size*0.95, y_size)]], dtype=np.int32)\n",
    "    mask_img = region_of_interest(binary_output, vertices)\n",
    "    mask_img_ = mask_img.copy()\n",
    "    mask_img_ = np.dstack((mask_img_, mask_img_, mask_img_)) * 255\n",
    "    cv2.polylines(mask_img_,[vertices],True,(0,255,0),3)\n",
    "    plt.imsave('./write_up_images/region_mask_'+img_name, mask_img_)\n",
    "#     mask_img = cv2.fillPoly(mask_img, \n",
    "#                             np.array([[[x_size*0.2, y_size], [x_size/2, y_size*0.7], [x_size*0.8, y_size]]], \n",
    "#                             dtype=np.int32), 0)\n",
    "    \n",
    "    # Finding lines with Hough Alg.\n",
    "    hough_mask_img, pts = hough_lines(mask_img, rho=2, theta=np.pi/180, min_line_len=20, max_line_gap=30, threshold=10)\n",
    "    binary_output_ = np.zeros_like(hough_mask_img[:,:,0])\n",
    "    binary_output_[(binary_output == 1) & (cv2.cvtColor(hough_mask_img, cv2.COLOR_RGB2GRAY) == 255)] = 1 \n",
    "    mask_img_ = mask_img.copy()\n",
    "    mask_img_ = np.dstack((mask_img_, mask_img_, mask_img_)) * 255\n",
    "    cv2.polylines(mask_img_,np.int32([pts]),True,(0,255,0),3)\n",
    "    plt.imsave('./write_up_images/lane_area_'+img_name, mask_img_)\n",
    "    plt.imsave('./write_up_images/hough_mask_'+img_name, hough_mask_img)\n",
    "    plt.imsave('./write_up_images/combo2_'+img_name, binary_output_, cmap='gray')\n",
    "\n",
    "    \n",
    "    # Warp\n",
    "    margin_x = 300\n",
    "    margin_y_top = 0\n",
    "    warp_img = warper(binary_output_, np.float32(pts), np.float32([[margin_x, margin_y_top], \n",
    "                                  [x_size - margin_x, margin_y_top], \n",
    "                                  [x_size - margin_x, y_size], \n",
    "                                  [margin_x, y_size]]))\n",
    "    plt.imsave('./write_up_images/warp_'+img_name, warp_img, cmap='gray')\n",
    "    \n",
    "#     window_width = 50\n",
    "#     window_height = 50\n",
    "#     margin = 50\n",
    "#     warp_img = warp_mask(warp_img, window_width, window_height, margin)\n",
    "#     plt.imsave('./write_up_images/warp2_'+img_name, warp_img)\n",
    "\n",
    "    # Curvature calculation\n",
    "    poly_warp_img, ploty_m, left_fit, right_fit, l_r = fit_polynomial(warp_img)\n",
    "    left_curv, right_curv = measure_curvature_pixels(ploty_m, left_fit, right_fit)\n",
    "    beta = 1\n",
    "    if l_r == 0:\n",
    "        curvature = left_curv * beta + right_curv * (1-beta)\n",
    "    else:\n",
    "        curvature = left_curv * (1-beta) + right_curv * beta\n",
    "    plt.imsave('./write_up_images/poly_warp_img_'+img_name, poly_warp_img)\n",
    "    print(\"img:{} 's curvature:{}\".format(img_name, round(curvature, 2)))\n",
    "        \n",
    "        \n",
    "    # Draw\n",
    "    color_binary_output_ = binary_output_.copy()\n",
    "    color_binary_output_[0:int(y_size*0.65), :] = 0\n",
    "    lanes_overlay = np.zeros_like(dst_)\n",
    "    lanes_overlay[color_binary_output_ == 1] = [255, 0, 0]\n",
    "    \n",
    "    overlay = dst_.copy()\n",
    "    pts = np.array(pts, np.int32)\n",
    "    cv2.fillPoly(overlay,[pts],(0,255,0))\n",
    "    cv2.addWeighted(overlay, 0.3, dst_, 0.7, 0, dst_)\n",
    "    cv2.addWeighted(lanes_overlay, 1.0, dst_, 1.0, 0, dst_)\n",
    "    cv2.putText(dst_, \"Radius of Curvature: {} m\".format(round(curvature, 2)), (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 4)\n",
    "    xm_per_pix = 3.7 / 700\n",
    "    center_bias = xm_per_pix * (x_size/2 - (pts[3][0] + pts[2][0])/2)\n",
    "    f = lambda x: \"right\" if x > 0 else \"left\"\n",
    "    cv2.putText(dst_, \"The car is {}m {} of center\".format(round(center_bias, 2), f(center_bias)), (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 4)\n",
    "    plt.imsave('./write_up_images/final_'+img_name, dst_)\n",
    "    \n",
    "    # Save images\n",
    "#     plt.imsave('./output_images/sobelx/'+'sobelx_'+os.path.split(fname)[-1], img_sobelx, cmap='gray')\n",
    "#     plt.imsave('./output_images/sobely/'+'sobely_'+os.path.split(fname)[-1], img_sobely, cmap='gray')\n",
    "#     plt.imsave('./output_images/mag/'+'mag_'+os.path.split(fname)[-1], img_mag, cmap='gray')\n",
    "#     plt.imsave('./output_images/dir/'+'dir_'+os.path.split(fname)[-1], img_dir, cmap='gray')\n",
    "#     plt.imsave('./output_images/hls/'+'hls_'+os.path.split(fname)[-1], hls_thresh_img, cmap='gray')\n",
    "#     plt.imsave('./output_images/combo/'+'combo_'+os.path.split(fname)[-1], binary_output, cmap='gray')\n",
    "#     plt.imsave('./output_images/undistort/'+'undistort_'+os.path.split(fname)[-1], dst)\n",
    "    plt.imsave('./output_images/draw/'+os.path.split(fname)[-1], dst_)\n",
    "    plt.imsave('./output_images/mask/'+os.path.split(fname)[-1], mask_img)\n",
    "#     plt.imsave('./output_images/color_change/'+os.path.split(fname)[-1], dst)\n",
    "#     plt.imsave('./output_images/weighted/'+os.path.split(fname)[-1], weighted_img(dst_, mask_img))\n",
    "    plt.imsave('./output_images/warp/'+os.path.split(fname)[-1], warp_img, cmap='gray')\n",
    "    plt.imsave('./output_images/precise_combo/'+os.path.split(fname)[-1], binary_output_, cmap='gray')\n",
    "    plt.imsave('./output_images/fit_poly/'+os.path.split(fname)[-1], poly_warp_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope_Q_l, slope_Q_r = np.array([]), np.array([])\n",
    "temp_pts = [[], [], [], []]\n",
    "\n",
    "def process_image(img):\n",
    "    \n",
    "#     img = cv2.imread(fname)\n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Undistortion\n",
    "    dst = cv2.undistort(img, mtx, dist)\n",
    "    dst_ = copy.deepcopy(dst)\n",
    "    \n",
    "    # Color thresholding\n",
    "    hls_thresh_img = hls_select(dst, thresh2=(40, 255), thresh3=(90, 255))\n",
    "    mask_color_img = np.ones_like(dst) * 255\n",
    "    \n",
    "    # Color (S,L) enhancement\n",
    "    dst = cv2.cvtColor(dst, cv2.COLOR_RGB2HLS)\n",
    "    dst[(hls_thresh_img == 1), 1:3] += 70\n",
    "    dst = cv2.cvtColor(dst, cv2.COLOR_HLS2RGB)\n",
    "    dst = cv2.GaussianBlur(dst, (3, 3), 0)\n",
    "    \n",
    "    # Gradients thresholding\n",
    "    img_sobelx = abs_sobel_thresh(dst, 'x', 20, 255)\n",
    "    img_sobely = abs_sobel_thresh(dst, 'y', 40, 255)\n",
    "    img_mag = mag_thresh(dst, 7, (40, 255))\n",
    "    img_dir = dir_threshold(dst, 5, (0.7, 1.3))\n",
    "    \n",
    "    # Threshold combination\n",
    "    binary_output = np.zeros_like(img[:,:,0])\n",
    "    binary_output[((img_sobelx == 1) & (img_sobely == 1)) | (hls_thresh_img == 1)] = 1\n",
    "    \n",
    "    # Region masking\n",
    "    y_size, x_size = img.shape[0], img.shape[1]\n",
    "    vertices = np.array([[(x_size*0.05, y_size), \n",
    "                          (x_size*0.43, y_size*0.65), \n",
    "                          (x_size*0.63, y_size*0.65), \n",
    "                          (x_size*0.95, y_size)]], dtype=np.int32)\n",
    "    mask_img = region_of_interest(binary_output, vertices)\n",
    "#     mask_img = cv2.fillPoly(mask_img, \n",
    "#                             np.array([[[x_size*0.2, y_size], [x_size/2, y_size*0.7], [x_size*0.8, y_size]]], \n",
    "#                             dtype=np.int32), 0)\n",
    "    \n",
    "    # Finding lines with Hough Alg.\n",
    "    mask_img, pts = hough_lines(mask_img, rho=2, theta=np.pi/180, min_line_len=30, max_line_gap=50, threshold=15)\n",
    "    left_slope, right_slope = np.arctan((pts[0][1] - pts[3][1]) / (pts[0][0] - pts[3][0])), np.arctan((pts[1][1] - pts[2][1]) / (pts[1][0] - pts[2][0]))\n",
    "    global slope_Q_l, slope_Q_r, temp_pts\n",
    "    if len(slope_Q_l) > 0 and np.abs(left_slope - np.average(slope_Q_l, axis=0)) > 10:\n",
    "        pts[0], pts[3] = temp_pts[0], temp_pts[3]\n",
    "    else:\n",
    "        slope_Q_l = np.insert(slope_Q_l, 0, np.arctan((pts[0][1] - pts[3][1]) / (pts[0][0] - pts[3][0])), axis=0)\n",
    "        temp_pts[0], temp_pts[3] = pts[0], pts[3]\n",
    "        if len(slope_Q_l) == 10:\n",
    "            slope_Q_l = np.delete(slope_Q_l, 9, axis=0)\n",
    "    \n",
    "    if len(slope_Q_r) > 0 and np.abs(right_slope - np.average(slope_Q_r, axis=0)) > 10:\n",
    "        pts[1], pts[2] = temp_pts[1], temp_pts[2]\n",
    "    else:\n",
    "        slope_Q_r = np.insert(slope_Q_l, 0, np.arctan((pts[1][1] - pts[2][1]) / (pts[1][0] - pts[2][0])), axis=0)\n",
    "        temp_pts[1], temp_pts[2] = pts[1], pts[2]\n",
    "        if len(slope_Q_r) == 10:\n",
    "            slope_Q_r = np.delete(slope_Q_r, 9, axis=0)\n",
    "    \n",
    "#     if pts == False:\n",
    "#         plt.imsave('failed_mask.png', mask_img)\n",
    "#         plt.imsave('failed_img.png', img)\n",
    "#         plt.imsave('failed_combo.png', binary_output)\n",
    "#         plt.imsave('failed_hls.png', hls_thresh_img)\n",
    "#         plt.imsave('failed_sobelx.png', img_sobelx)\n",
    "#         pts = temp_pts\n",
    "#     else:\n",
    "#         temp_pts = pts\n",
    "    binary_output_ = np.zeros_like(mask_img[:,:,0])\n",
    "    binary_output_[(binary_output == 1) & (cv2.cvtColor(mask_img, cv2.COLOR_RGB2GRAY) == 255)] = 1    \n",
    "    \n",
    "    \n",
    "    # Warp\n",
    "    margin_x = 300\n",
    "    margin_y_top = 0\n",
    "    warp_img = warper(binary_output_, np.float32(pts), np.float32([[margin_x, margin_y_top], \n",
    "                                  [x_size - margin_x, margin_y_top], \n",
    "                                  [x_size - margin_x, y_size], \n",
    "                                  [margin_x, y_size]]))\n",
    "#     window_width = 50\n",
    "#     window_height = 50\n",
    "#     margin = 50\n",
    "#     warp_img = warp_mask(warp_img, window_width, window_height, margin)\n",
    "\n",
    "    # Curvature calculation\n",
    "    poly_warp_img, ploty_m, left_fit, right_fit, l_r = fit_polynomial(cv2.cvtColor(warp_img, cv2.COLOR_RGB2GRAY))\n",
    "    left_curv, right_curv = measure_curvature_pixels(ploty_m, left_fit, right_fit)\n",
    "    beta = 1\n",
    "    if l_r == 0:\n",
    "        curvature = left_curv * beta + right_curv * (1-beta)\n",
    "    else:\n",
    "        curvature = left_curv * (1-beta) + right_curv * beta\n",
    "    \n",
    "    # Draw\n",
    "    color_binary_output_ = binary_output_.copy()\n",
    "    color_binary_output_[0:int(y_size*0.65), :] = 0\n",
    "    lanes_overlay = np.zeros_like(dst_)\n",
    "    lanes_overlay[color_binary_output_ == 1] = [255, 0, 0]\n",
    "    \n",
    "    overlay = dst_.copy()\n",
    "    pts = np.array(pts, np.int32)\n",
    "    cv2.fillPoly(overlay,[pts],(0,255,0))\n",
    "    cv2.addWeighted(overlay, 0.3, dst_, 0.7, 0, dst_)\n",
    "    cv2.addWeighted(lanes_overlay, 1.0, dst_, 1.0, 0, dst_)\n",
    "    cv2.putText(dst_, \"Radius of Curvature: {} m\".format(round(curvature, 2)), (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 4)\n",
    "    xm_per_pix = 3.7 / 700\n",
    "    center_bias = xm_per_pix * (x_size/2 - (pts[3][0] + pts[2][0])/2)\n",
    "    f = lambda x: \"right\" if x > 0 else \"left\"\n",
    "    cv2.putText(dst_, \"The car is {}m {} of center\".format(round(center_bias, 2), f(center_bias)), (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 4)\n",
    "    \n",
    "    # Create canvas\n",
    "    canvas = np.zeros((y_size, x_size, 3))\n",
    "    # Resize Images\n",
    "    binary_output_ = cv2.resize(binary_output_, (int(x_size * 0.5), int(y_size * 0.5)))\n",
    "    dst_ = cv2.resize(dst_, (int(x_size * 0.5), int(y_size * 0.5)))\n",
    "    poly_warp_img = cv2.resize(poly_warp_img, (int(x_size * 0.5), int(y_size * 0.5)))\n",
    "    # Fill canvas\n",
    "    half_x_size, half_y_size = int(0.5*x_size), int(0.5*y_size)\n",
    "    canvas[0:half_y_size, 0:half_x_size,:] = cv2.cvtColor(binary_output_, cv2.COLOR_GRAY2RGB) * 255\n",
    "    canvas[0:half_y_size, half_x_size:, :] = poly_warp_img\n",
    "    canvas[half_y_size:, 0:half_x_size,:] = dst_\n",
    "    \n",
    "#     return canvas\n",
    "    return dst_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video processed_project_video.mp4\n",
      "[MoviePy] Writing video processed_project_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 862/1261 [27:31<05:07,  1.30it/s]    "
     ]
    }
   ],
   "source": [
    "import time\n",
    "white_output = 'processed_project_video.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"processed_project_video.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = inspect.getsource(fit_polynomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def region_of_interest(img, vertices):\n",
      "    \"\"\"\n",
      "    Applies an image mask.\n",
      "\n",
      "    Only keeps the region of the image defined by the polygon\n",
      "    formed from `vertices`. The rest of the image is set to black.\n",
      "    `vertices` should be a numpy array of integer points.\n",
      "    \"\"\"\n",
      "    # defining a blank mask to start with\n",
      "    mask = np.zeros_like(img)\n",
      "\n",
      "    # defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
      "    if len(img.shape) > 2:\n",
      "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
      "        ignore_mask_color = (255,) * channel_count\n",
      "    else:\n",
      "        ignore_mask_color = 255\n",
      "\n",
      "    # filling pixels inside the polygon defined by \"vertices\" with the fill color\n",
      "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
      "\n",
      "    # returning the image only where mask pixels are nonzero\n",
      "    masked_image = cv2.bitwise_and(img, mask)\n",
      "    return masked_image\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
